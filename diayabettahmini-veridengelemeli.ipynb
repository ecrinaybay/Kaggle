{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228},{"sourceId":1847406,"sourceType":"datasetVersion","datasetId":1098645}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pandas scikit-fuzzy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:08:52.799044Z","iopub.execute_input":"2025-05-01T13:08:52.799335Z","iopub.status.idle":"2025-05-01T13:08:58.474188Z","shell.execute_reply.started":"2025-05-01T13:08:52.799302Z","shell.execute_reply":"2025-05-01T13:08:58.472710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport skfuzzy as fuzz\nfrom skfuzzy import control as ctrl\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.svm import SVC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:08:58.477221Z","iopub.execute_input":"2025-05-01T13:08:58.477528Z","iopub.status.idle":"2025-05-01T13:09:00.442758Z","shell.execute_reply.started":"2025-05-01T13:08:58.477501Z","shell.execute_reply":"2025-05-01T13:09:00.441758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Veri setini oku\ndata = pd.read_csv('/kaggle/input/pima-india/diabetes.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:00.443775Z","iopub.execute_input":"2025-05-01T13:09:00.444287Z","iopub.status.idle":"2025-05-01T13:09:00.469495Z","shell.execute_reply.started":"2025-05-01T13:09:00.444262Z","shell.execute_reply":"2025-05-01T13:09:00.468549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Özellik mühendisliği: Yeni özellikler ekleyelim\ndata['Glucose_BMI_Ratio'] = data['Glucose'] / (data['BMI'] + 0.001)\ndata['Age_BMI_Product'] = data['Age'] * data['BMI'] / 100\ndata['Glucose_BP_Product'] = data['Glucose'] * data['BloodPressure'] / 100\ndata['Insulin_Glucose_Index'] = (data['Insulin'] * data['Glucose']) / 405\ndata['BMI_Pregnancies_Product'] = data['BMI'] * (data['Pregnancies'] + 1) / 10\ndata['DiabetesPedigreeFunction_Age'] = data['DiabetesPedigreeFunction'] * data['Age'] / 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:00.470482Z","iopub.execute_input":"2025-05-01T13:09:00.470741Z","iopub.status.idle":"2025-05-01T13:09:00.490451Z","shell.execute_reply.started":"2025-05-01T13:09:00.470700Z","shell.execute_reply":"2025-05-01T13:09:00.489340Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu özellik mühendisliği adımları, veri setindeki bazı özelliklerin (özellikle Glucose, BMI, Age, vb.) kombinasyonlarıyla yeni özellikler yaratmayı amaçlar. Bu tür yeni özellikler, modelin daha iyi performans göstermesine yardımcı olabilir çünkü bu ilişkiler, veri setindeki temel desenleri daha iyi yakalayabilir. Şimdi her bir yeni özelliği açıklayalım:\n\n1. **`Glucose_BMI_Ratio`**:\n   ```python\n   data['Glucose_BMI_Ratio'] = data['Glucose'] / (data['BMI'] + 0.001)\n   ```\n   - **Açıklama**: Bu özellik, **Glucose** ve **BMI** arasındaki oranı hesaplar. **BMI**'nin 0 olma ihtimaline karşı (bölme işleminde hata olmaması için) 0.001 eklenmiştir. Glukoz seviyesi ile BMI arasındaki ilişkiyi modellemek amacıyla kullanılabilir.\n\n2. **`Age_BMI_Product`**:\n   ```python\n   data['Age_BMI_Product'] = data['Age'] * data['BMI'] / 100\n   ```\n   - **Açıklama**: Bu özellik, **Age** (yaş) ve **BMI**'yi çarpar ve 100'e böler. Bu, yaşın ve vücut kitle indeksinin bir bileşkesi olarak, her iki faktörün birlikte nasıl bir etkisi olduğunu modellemeye yardımcı olabilir.\n\n3. **`Glucose_BP_Product`**:\n   ```python\n   data['Glucose_BP_Product'] = data['Glucose'] * data['BloodPressure'] / 100\n   ```\n   - **Açıklama**: Bu özellik, **Glucose** (glukoz) ve **BloodPressure** (kan basıncı) arasındaki ilişkiyi modellemeye çalışır. Glukoz ve kan basıncı arasındaki etkileşim, özellikle diyabet ve hipertansiyon gibi hastalıkların ilişkisi açısından önemlidir.\n\n4. **`Insulin_Glucose_Index`**:\n   ```python\n   data['Insulin_Glucose_Index'] = (data['Insulin'] * data['Glucose']) / 405\n   ```\n   - **Açıklama**: Bu özellik, **Insulin** (insülin) ve **Glucose** (glukoz) seviyelerinin bir indeksini oluşturur. **405** değeri, genellikle bu iki değişkenin ilişkisinin biyolojik bir ölçüsüdür. Bu özellik, insülin ve glukoz arasındaki etkileşimi modellemeye yardımcı olabilir.\n\n5. **`BMI_Pregnancies_Product`**:\n   ```python\n   data['BMI_Pregnancies_Product'] = data['BMI'] * (data['Pregnancies'] + 1) / 10\n   ```\n   - **Açıklama**: Bu özellik, **BMI** ve **Pregnancies** (gebelik sayısı) arasındaki çarpımı hesaplar. Gebelik sayısına 1 eklenmiş çünkü bazı verilerde gebelik sayısının sıfır olması mümkündür ve bu da sıfırla bölme hatasına yol açabilir. Özellik, gebelik sayısının ve BMI'nin birlikte nasıl bir etkisi olduğunu modellemeye yardımcı olabilir.\n\n6. **`DiabetesPedigreeFunction_Age`**:\n   ```python\n   data['DiabetesPedigreeFunction_Age'] = data['DiabetesPedigreeFunction'] * data['Age'] / 10\n   ```\n   - **Açıklama**: Bu özellik, **DiabetesPedigreeFunction** (diyabet soy ağacı fonksiyonu) ile **Age** (yaş) arasındaki etkileşimi modellemeye çalışır. Soy ağacı fonksiyonu, bir kişinin genetik yatkınlığını gösteren bir ölçüdür. Bu özellik, genetik faktörler ve yaş arasındaki ilişkiyi dikkate alır.\n\nBu tür özellik mühendisliği, modelin daha anlamlı ve güçlü tahminler yapabilmesi için önemli olabilir çünkü veriler arasındaki ilişkiyi daha derinlemesine yakalar.","metadata":{}},{"cell_type":"code","source":"# Veriyi dengeleyelim (SMOTE olmadan)\n# Azınlık sınıfının örneklerini çoğaltalım\ndiabetes_positive = data[data['Outcome'] == 1]\ndiabetes_negative = data[data['Outcome'] == 0]\n\n# Pozitif örnekleri 3 kez çoğaltalım\ndiabetes_positive_upsampled = pd.concat([diabetes_positive] * 3)\nbalanced_data = pd.concat([diabetes_negative, diabetes_positive_upsampled])\n\n# Veriyi karıştıralım\nbalanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Veriyi ayıralım\nX = balanced_data.drop(['Outcome'], axis=1)\ny = balanced_data['Outcome']\n\n# Eğitim ve test setlerine bölelim\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42, stratify=y)\n\n# Eksik değerleri doldur\nX_train = X_train.fillna(X_train.mean())\nX_test = X_test.fillna(X_train.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:00.492941Z","iopub.execute_input":"2025-05-01T13:09:00.493300Z","iopub.status.idle":"2025-05-01T13:09:00.536888Z","shell.execute_reply.started":"2025-05-01T13:09:00.493276Z","shell.execute_reply":"2025-05-01T13:09:00.535900Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu kod parçası, veri setinde dengesiz sınıf dağılımını dengelemeyi ve modelin eğitimine yönelik bazı ön işleme adımlarını içeriyor. Şimdi her bir adımı açıklayalım:\n\n1. **Azınlık sınıfını çoğaltma (Oversampling):**\n   ```python\n   diabetes_positive = data[data['Outcome'] == 1]\n   diabetes_negative = data[data['Outcome'] == 0]\n   ```\n   - **Açıklama**: Burada, **Outcome** (sonuç) sütununa göre veri seti iki gruba ayrılıyor. `diabetes_positive`, diyabeti olan (sonuç = 1) örnekleri içerirken, `diabetes_negative` diyabeti olmayan (sonuç = 0) örnekleri içeriyor.\n\n2. **Azınlık sınıfının örneklerini çoğaltma:**\n   ```python\n   diabetes_positive_upsampled = pd.concat([diabetes_positive] * 3)\n   ```\n   - **Açıklama**: Azınlık sınıfı (diyabeti olan örnekler, `diabetes_positive`) üç kez çoğaltılıyor. Bu, azınlık sınıfını daha fazla örnekle çoğaltarak sınıflar arasındaki dengesizliği giderir. Burada, `pd.concat([diabetes_positive] * 3)` işlemiyle, **diyabetli örnekler** üç katına çıkarılıyor.\n\n3. **Veriyi dengeleme (Balance etme):**\n   ```python\n   balanced_data = pd.concat([diabetes_negative, diabetes_positive_upsampled])\n   ```\n   - **Açıklama**: Şimdi, çoğaltılmış diyabetli örnekler (`diabetes_positive_upsampled`) ile diyabeti olmayan örnekler (`diabetes_negative`) birleştiriliyor. Bu işlem, sınıflar arasındaki dengeyi sağlamak için kullanılır.\n\n4. **Veriyi karıştırma (Shuffle):**\n   ```python\n   balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n   ```\n   - **Açıklama**: Karışık bir sıralama yapmak için, `sample(frac=1)` kullanılarak veriler karıştırılıyor. `frac=1`, tüm verilerin karıştırılmasını sağlar. `random_state=42` belirli bir rastgelelikin sağlanması için kullanılır (sonuçların tutarlı olmasını sağlar). `reset_index(drop=True)` ise karıştırılan verinin indeksini sıfırlayarak, eski indekslerin veri setinde saklanmasını engeller.\n\n5. **Veriyi ayırma (Features ve hedef değişken):**\n   ```python\n   X = balanced_data.drop(['Outcome'], axis=1)\n   y = balanced_data['Outcome']\n   ```\n   - **Açıklama**: Burada, bağımsız değişkenler (özellikler) ve bağımlı değişken (hedef) ayrılır. `X`, tüm sütunları içerirken, **Outcome** sütunu çıkarılır ve bu sütun **y** olarak atanır.\n\n6. **Eğitim ve test setlerine ayırma:**\n   ```python\n   X_train, X_test, y_train, y_test = train_test_split(\n       X, y, test_size=0.25, random_state=42, stratify=y)\n   ```\n   - **Açıklama**: Veriyi eğitim ve test setlerine böler. **test_size=0.25** ile test seti %25 oranında ayrılır. **stratify=y**, sınıf dengesinin eğitim ve test setlerine doğru bir şekilde dağılmasını sağlar (diyabetli ve diyabetsiz örneklerin her iki sette de benzer oranlarda bulunmasını sağlar).\n\n7. **Eksik değerlerin doldurulması:**\n   ```python\n   X_train = X_train.fillna(X_train.mean())\n   X_test = X_test.fillna(X_train.mean())\n   ```\n   - **Açıklama**: Eksik (NaN) değerlere sahip olan özelliklerin, eğitim verisindeki ortalama değeri ile doldurulması sağlanır. Bu, modelin eksik verilere karşı dayanıklı olmasını sağlar. `X_train.mean()` ile eğitim setindeki her sütunun ortalama değeri alınır ve bu ortalama değerle hem eğitim hem de test setindeki eksik veriler doldurulur. Bu şekilde, test setindeki eksik değerler de eğitim setinin istatistiklerine dayanarak tamamlanmış olur.\n\nBu adımlar, dengesiz veri setlerinde sınıflar arasındaki farkı azaltmaya yardımcı olur ve eksik veri durumunda daha sağlam bir model eğitimi sağlar.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport skfuzzy as fuzz\nfrom skfuzzy import control as ctrl\n\ndef create_fuzzy_system():\n    # Ana değişkenler\n    glucose = ctrl.Antecedent(np.arange(0, 201, 1), 'glucose')\n    bmi = ctrl.Antecedent(np.arange(0, 51, 1), 'bmi')\n    age = ctrl.Antecedent(np.arange(20, 81, 1), 'age')\n    bloodpressure = ctrl.Antecedent(np.arange(0, 123, 1), 'bloodpressure')\n    pedigree = ctrl.Antecedent(np.arange(0, 3.1, 0.1), 'pedigree')\n\n    diabetes_risk = ctrl.Consequent(np.arange(0, 101, 1), 'diabetes_risk')\n\n    # Glukoz için üyelik fonksiyonları (daha güncel)\n    glucose['very_low'] = fuzz.trimf(glucose.universe, [0, 30, 60])\n    glucose['low'] = fuzz.trimf(glucose.universe, [50, 80, 100])\n    glucose['normal'] = fuzz.trimf(glucose.universe, [70, 100, 125])\n    glucose['high'] = fuzz.trimf(glucose.universe, [120, 150, 170])\n    glucose['very_high'] = fuzz.trimf(glucose.universe, [160, 190, 200])\n\n    # BMI için üyelik fonksiyonları\n    bmi['underweight'] = fuzz.trimf(bmi.universe, [0, 15, 18])\n    bmi['normal'] = fuzz.trimf(bmi.universe, [18, 22, 24])\n    bmi['overweight'] = fuzz.trimf(bmi.universe, [24, 27, 30])\n    bmi['obese'] = fuzz.trimf(bmi.universe, [29, 32, 36])\n    bmi['extremely_obese'] = fuzz.trimf(bmi.universe, [35, 40, 50])\n\n    # Yaş için üyelik fonksiyonları\n    age['young'] = fuzz.trimf(age.universe, [20, 25, 35])\n    age['middle'] = fuzz.trimf(age.universe, [30, 45, 60])\n    age['old'] = fuzz.trimf(age.universe, [55, 70, 80])\n\n    # Kan basıncı için üyelik fonksiyonları\n    bloodpressure['normal'] = fuzz.trimf(bloodpressure.universe, [60, 75, 85])\n    bloodpressure['elevated'] = fuzz.trimf(bloodpressure.universe, [80, 90, 100])\n    bloodpressure['high'] = fuzz.trimf(bloodpressure.universe, [95, 110, 120])\n\n    # Pedigree için üyelik fonksiyonları\n    pedigree['low'] = fuzz.trimf(pedigree.universe, [0, 0.5, 1])\n    pedigree['medium'] = fuzz.trimf(pedigree.universe, [0.8, 1.5, 2])\n    pedigree['high'] = fuzz.trimf(pedigree.universe, [1.8, 2.5, 3])\n\n    # Diyabet riski için üyelik fonksiyonları\n    diabetes_risk['very_low'] = fuzz.trimf(diabetes_risk.universe, [0, 10, 20])\n    diabetes_risk['low'] = fuzz.trimf(diabetes_risk.universe, [15, 30, 45])\n    diabetes_risk['medium'] = fuzz.trimf(diabetes_risk.universe, [40, 55, 70])\n    diabetes_risk['high'] = fuzz.trimf(diabetes_risk.universe, [65, 80, 90])\n    diabetes_risk['very_high'] = fuzz.trimf(diabetes_risk.universe, [85, 95, 100])\n\n    # Kurallar\n    rules = [\n        # Çok düşük risk\n        ctrl.Rule(glucose['very_low'] & bmi['normal'] & age['young'] & pedigree['low'], diabetes_risk['very_low']),\n        ctrl.Rule(glucose['low'] & bmi['normal'] & age['young'] & bloodpressure['normal'], diabetes_risk['very_low']),\n\n        # Düşük risk\n        ctrl.Rule(glucose['normal'] & bmi['normal'] & bloodpressure['normal'], diabetes_risk['low']),\n        ctrl.Rule(glucose['low'] & bmi['normal'] & age['middle'] & pedigree['low'], diabetes_risk['low']),\n        ctrl.Rule(glucose['low'] & bmi['overweight'] & age['young'] & pedigree['low'], diabetes_risk['low']),\n\n        # Orta risk\n        ctrl.Rule(glucose['normal'] & bmi['overweight'], diabetes_risk['medium']),\n        ctrl.Rule(glucose['normal'] & age['old'], diabetes_risk['medium']),\n        ctrl.Rule(glucose['low'] & bmi['obese'], diabetes_risk['medium']),\n        ctrl.Rule(glucose['normal'] & bloodpressure['elevated'], diabetes_risk['medium']),\n        ctrl.Rule(glucose['normal'] & pedigree['high'], diabetes_risk['medium']),\n        ctrl.Rule(glucose['high'] & bloodpressure['normal'] & pedigree['low'], diabetes_risk['medium']),\n\n        # Yüksek risk\n        ctrl.Rule(glucose['high'] & bmi['normal'], diabetes_risk['high']),\n        ctrl.Rule(glucose['high'] & age['middle'], diabetes_risk['high']),\n        ctrl.Rule(glucose['normal'] & bmi['obese'] & age['old'], diabetes_risk['high']),\n        ctrl.Rule(glucose['high'] & bloodpressure['elevated'], diabetes_risk['high']),\n        ctrl.Rule(glucose['normal'] & bmi['extremely_obese'], diabetes_risk['high']),\n        ctrl.Rule(glucose['normal'] & bloodpressure['high'], diabetes_risk['high']),\n        ctrl.Rule(glucose['high'] & pedigree['medium'], diabetes_risk['high']),\n\n        # Çok yüksek risk\n        ctrl.Rule(glucose['very_high'], diabetes_risk['very_high']),\n        ctrl.Rule(glucose['high'] & bmi['obese'], diabetes_risk['very_high']),\n        ctrl.Rule(glucose['high'] & bloodpressure['high'] & age['old'], diabetes_risk['very_high']),\n        ctrl.Rule(glucose['high'] & bmi['overweight'] & pedigree['high'], diabetes_risk['very_high']),\n        ctrl.Rule(glucose['high'] & bmi['obese'] & age['old'] & pedigree['high'], diabetes_risk['very_high']),\n        ctrl.Rule(glucose['very_high'] & pedigree['high'], diabetes_risk['very_high']),\n    ]\n\n    return rules, glucose, bmi, age, bloodpressure, pedigree, diabetes_risk\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:00.537817Z","iopub.execute_input":"2025-05-01T13:09:00.538102Z","iopub.status.idle":"2025-05-01T13:09:00.558118Z","shell.execute_reply.started":"2025-05-01T13:09:00.538081Z","shell.execute_reply":"2025-05-01T13:09:00.557053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu kod parçası, diyabet riski tahmin etmek için bir **bulanık mantık (fuzzy logic)** sistemi oluşturuyor. Fuzzy logic, klasik (kesin) mantıktan farklı olarak, belirsizlikleri ve belirsiz durumları modelleyebilmek için kullanılır. Diyabet riski gibi bir durumu daha gerçekçi şekilde modellemek için uygundur çünkü birçok faktörün etkileşimi ve sürekli değerler arasında belirsizlikler vardır.\n\nŞimdi, kodun her bir bölümünü detaylı bir şekilde açıklayalım:\n\n### 1. **Değişkenlerin Tanımlanması**\n   - `glucose`, `bmi`, `age`, `bloodpressure`, `pedigree`: Bunlar, diyabet riskini etkileyebilecek temel değişkenlerdir. Bu değişkenler **antecedent** olarak tanımlanır, yani sistemin girdilerini temsil eder.\n   - `diabetes_risk`: Bu, sistemin çıktısıdır ve **consequent** olarak tanımlanır. Bu, kişinin diyabet riskini gösteren değeri temsil eder.\n\n### 2. **Üyelik Fonksiyonlarının Tanımlanması**\n   Üyelik fonksiyonları, belirli bir değerin, o değerin ait olduğu **fuzzy (bulanık)** kümeye ne kadar dahil olduğunu gösterir. Bu kümeler, belirli değerler aralığında her değişken için belirlenmiştir.\n\n   - **Glukoz (glucose)** için üyelik fonksiyonları:\n     - `very_low`, `low`, `normal`, `high`, `very_high`: Glukoz seviyesinin çok düşükten çok yüksek seviyeye kadar beş kategoriye ayrılması.\n   - **BMI (body mass index)** için üyelik fonksiyonları:\n     - `underweight`, `normal`, `overweight`, `obese`, `extremely_obese`: Kişinin BMI değerine göre vücut ağırlık durumunun sınıflandırılması.\n   - **Yaş (age)** için üyelik fonksiyonları:\n     - `young`, `middle`, `old`: Yaş kategorileri (genç, orta yaşlı, yaşlı).\n   - **Kan basıncı (bloodpressure)** için üyelik fonksiyonları:\n     - `normal`, `elevated`, `high`: Kan basıncı seviyeleri (normal, yüksek, çok yüksek).\n   - **Pedigree (diyabet soyağacı fonksiyonu)** için üyelik fonksiyonları:\n     - `low`, `medium`, `high`: Kişinin diyabet geçmişi (ailede diyabet olup olmadığı) için kategoriler.\n\n   Bu üyelik fonksiyonları, her değişkenin değerlerinin hangi kategorilere girdiğini gösterir ve her kategoriye bir üyelik derecesi atanır. Bu dereceler, değişkenin o kümeye ait olma derecesini belirtir (0 ile 1 arasında).\n\n### 3. **Kuralların Tanımlanması**\n   Kurallar, fuzzy logic sisteminde **\"IF-THEN\"** şeklinde belirli bir ilişkiyi tanımlar. Bu kurallar, değişkenlerin değerlerine göre çıktıyı belirler. Burada, **diyabet riski** (diabetes_risk) ile ilgili çeşitli kurallar oluşturulmuş:\n\n   - **Çok düşük risk**: Glukoz seviyesi çok düşük, BMI normal, yaş genç, pedigree düşük olduğunda diyabet riski çok düşük olur.\n   - **Düşük risk**: Glukoz seviyesi normal, BMI normal, kan basıncı normal olduğunda diyabet riski düşük olur.\n   - **Orta risk**: Glukoz seviyesi normal, BMI aşırı kilolu olduğunda veya yaşlı olduğunda diyabet riski orta seviyede olur.\n   - **Yüksek risk**: Glukoz seviyesi yüksek, BMI normal veya yaş orta seviyede olduğunda diyabet riski yüksek olur.\n   - **Çok yüksek risk**: Glukoz seviyesi çok yüksek, BMI aşırı kilolu, yaşlılık ve yüksek kan basıncı ile birlikte diyabet riski çok yüksek olur.\n\n   Her kural, farklı değişkenlerin (glukoz, BMI, yaş, kan basıncı, pedigree) çeşitli kombinasyonlarına dayanarak bir çıktı (diabetes_risk) verir. Kurallar, diyabet riskinin seviyesini belirler.\n\n### 4. **Fonksiyonların ve Kuralların Sisteme Eklenmesi**\n   Bu üyelik fonksiyonları ve kurallar, fuzzy logic sistemine eklenir. `ctrl.Rule` fonksiyonu ile her bir **IF-THEN** kuralı tanımlanır. Bu kurallar, sistemin nasıl çalışacağına dair kararlar alır.\n\n### 5. **Fuzzy Kontrol Sistemi**\n   Bu fonksiyonlar ve kurallar bir araya getirilerek bir **fuzzy kontrol sistemi** oluşturulur. Fuzzy mantık, kesin sınırlar yerine üyelik dereceleri ile çalıştığı için, belirsizliği ve belirsiz veriyi hesaba katarak daha esnek ve gerçekçi sonuçlar elde edilir.\n\n### Özetle:\nBu kod, bir kişinin diyabet riskini tahmin etmek için kullanılan **fuzzy logic** (bulanık mantık) tabanlı bir sistem oluşturur. Sistemde, **glukoz**, **BMI**, **yaş**, **kan basıncı** ve **pedigree** gibi girdiler, belirli üyelik fonksiyonlarıyla kategoriye ayrılır ve kurallar aracılığıyla bu değişkenlere göre **diyabet riski** (çıkış değeri) hesaplanır.\n\nBu tür bir sistem, değişkenler arasındaki belirsiz ilişkileri modelleyerek daha doğru ve esnek tahminler yapılmasını sağlar.","metadata":{}},{"cell_type":"code","source":"# Bulanık risk hesaplama fonksiyonu\ndef calculate_fuzzy_risk(X_data):\n    rules, glucose, bmi, age, bloodpressure, pedigree, diabetes_risk = create_fuzzy_system()\n    \n    # Bulanık kontrol sistemi\n    diabetes_ctrl = ctrl.ControlSystem(rules)\n    \n    fuzzy_risks = []\n    \n    for idx, row in X_data.iterrows():\n        try:\n            # Yeni bir simülasyon oluştur (her örnek için yeni simülasyon gerekli)\n            diabetes_sim = ctrl.ControlSystemSimulation(diabetes_ctrl)\n            \n            # Değerleri ata\n            diabetes_sim.input['glucose'] = row['Glucose']\n            diabetes_sim.input['bmi'] = row['BMI']\n            diabetes_sim.input['age'] = row['Age']\n            diabetes_sim.input['bloodpressure'] = row['BloodPressure']\n            diabetes_sim.input['pedigree'] = row['DiabetesPedigreeFunction']\n            \n            # Hesaplama yap\n            diabetes_sim.compute()\n            risk_score = diabetes_sim.output['diabetes_risk']\n            fuzzy_risks.append(risk_score)\n        except Exception as e:\n            # Hata durumunda orta risk değeri atayalım\n            fuzzy_risks.append(50)\n            \n    return np.array(fuzzy_risks).reshape(-1, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:00.559221Z","iopub.execute_input":"2025-05-01T13:09:00.559542Z","iopub.status.idle":"2025-05-01T13:09:00.582292Z","shell.execute_reply.started":"2025-05-01T13:09:00.559514Z","shell.execute_reply":"2025-05-01T13:09:00.581299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu kod, verilen özellikler (glukoz, BMI, yaş, kan basıncı, soy geçmişi) kullanarak **fuzzy logic** (bulanık mantık) sistemiyle **diyabet riskini** hesaplayan bir fonksiyondur. Fonksiyon, her bir örnek için diyabet riskini bulanık bir değer (0 ile 100 arasında) olarak döndüren bir hesaplama yapar.\n\nŞimdi, adım adım ne yaptığını açıklayayım:\n\n### 1. **`create_fuzzy_system()` fonksiyonunun çağrılması**\n   - Bu fonksiyon, daha önce tanımlanan bulanık mantık sistemini oluşturur ve gerekli tüm üyelik fonksiyonları, kurallar ve çıktı değişkenleri ile bir **bulanık kontrol sistemi** (`ControlSystem`) oluşturur.\n   - Bu sistem, `glucose`, `bmi`, `age`, `bloodpressure`, `pedigree` gibi girdilere dayalı olarak **diyabet riski** (`diabetes_risk`) çıktısını hesaplamak için kullanılır.\n\n### 2. **Bulanık Kontrol Sistemi (`ControlSystem`) oluşturulması**\n   - `diabetes_ctrl = ctrl.ControlSystem(rules)`: Bu satırda, daha önce tanımlanan kurallar (`rules`) ile bir **bulanık kontrol sistemi** oluşturuluyor.\n   - Bu kontrol sistemi, belirtilen kurallar aracılığıyla girdi verilerini alır ve çıktı verisini hesaplar.\n\n### 3. **Simülasyon Başlatılması**\n   - Her bir veri satırı (örnek) için ayrı bir simülasyon yapılır. Bu simülasyon, her bir örneğin özelliklerine göre diyabet riski skorunu hesaplamak için gereklidir.\n   - `diabetes_sim = ctrl.ControlSystemSimulation(diabetes_ctrl)`: Yeni bir **simülasyon** başlatılır. Bu simülasyon, `diabetes_ctrl` kontrol sistemine dayalı olarak çalışır.\n\n### 4. **Girdi Değerlerinin Verilmesi**\n   - Simülasyonun her bir örneği için, verinin her bir özelliği (`Glucose`, `BMI`, `Age`, `BloodPressure`, `DiabetesPedigreeFunction`) ilgili fuzzy mantık sistemine aktarılır.\n   - `diabetes_sim.input['glucose'] = row['Glucose']`: Bu satırda, `X_data` veri çerçevesindeki her bir satırın (örneğin bir kişinin verileri) `glucose`, `bmi`, `age`, `bloodpressure` ve `pedigree` değerleri, simülasyona girdi olarak verilir.\n\n### 5. **Bulanık Hesaplamanın Yapılması**\n   - `diabetes_sim.compute()`: Bu satır, simülasyonu çalıştırır ve **diyabet riski** için gerekli hesaplamaları yapar.\n   - `risk_score = diabetes_sim.output['diabetes_risk']`: Hesaplanan diyabet riski değeri alınır. Bu değer, belirli bir kişinin diyabet riskini temsil eden bir **bulanık skor** olacaktır (0 ile 100 arasında).\n\n### 6. **Risk Skorlarının Listeye Eklenmesi**\n   - Her bir örnek için hesaplanan diyabet riski (`risk_score`), `fuzzy_risks` listesine eklenir. Bu liste, tüm örneklerin risk skorlarını içerir.\n\n### 7. **Hata Durumunun Ele Alınması**\n   - Eğer herhangi bir hata oluşursa (örneğin, veriler eksik veya geçersiz olduğunda), `except` bloğu devreye girer ve bu durumda diyabet riski olarak **orta risk (50)** atanır.\n   - `fuzzy_risks.append(50)`: Hata durumunda 50 değeri, orta düzeyde risk olarak kabul edilir.\n\n### 8. **Sonuçların Döndürülmesi**\n   - `np.array(fuzzy_risks).reshape(-1, 1)`: Hesaplanan risk skorları, bir **numpy array** formatına dönüştürülür ve ardından her skor tek bir sütunda olacak şekilde yeniden şekillendirilir (reshape). Bu, çıktının düzgün bir formatta olmasını sağlar.\n\n### Fonksiyonun Genel Çalışma Prensibi\nBu fonksiyon, veri kümesindeki her bir örneği (kişi) alır, her örneğin özelliklerini kullanarak bir fuzzy logic simülasyonu çalıştırır, diyabet riski skorunu hesaplar ve her bir örnek için bu risk skorlarını döndürür. Bu skorlar, diyabet riskini belirlemek için kullanılabilir. Eğer bir hata oluşursa, o örnek için ortalama bir risk (50) döndürülür.\n\n### Özetle:\n- **`X_data`** veri kümesindeki her örnek için **bulanık mantık** sistemine girdi verilir.\n- Girdi verilerine göre **diyabet riski** hesaplanır.\n- Hesaplanan riskler bir dizi olarak döndürülür.\n\nBu fonksiyon, kişilerin diyabet risklerini daha esnek bir şekilde hesaplamak için bulanık mantığı kullanır.","metadata":{}},{"cell_type":"code","source":"# Bulanık risk skorlarını hesapla\nfuzzy_risks_train = calculate_fuzzy_risk(X_train)\nfuzzy_risks_test = calculate_fuzzy_risk(X_test)\n\n# Bulanık risk skorları ile diğer özellikleri birleştir\nX_train_with_fuzzy = np.hstack((X_train.values, fuzzy_risks_train))\nX_test_with_fuzzy = np.hstack((X_test.values, fuzzy_risks_test))\n\n# Veriyi standartlaştır\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_with_fuzzy)\nX_test_scaled = scaler.transform(X_test_with_fuzzy)\n\n# Özellik isimleri (plot için)\nfeature_names = list(X_train.columns) + ['fuzzy_risk']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:00.583093Z","iopub.execute_input":"2025-05-01T13:09:00.583434Z","iopub.status.idle":"2025-05-01T13:09:25.471678Z","shell.execute_reply.started":"2025-05-01T13:09:00.583390Z","shell.execute_reply":"2025-05-01T13:09:25.470711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu kod, bulanık risk skorlarını hesapladıktan sonra, bu skorları eğitim ve test verilerine ekleyip verileri standartlaştırarak modelin eğitimine hazır hale getirmeyi amaçlıyor. Şimdi, her bir adımı açıklayalım:\n\n### 1. **Bulanık Risk Skorlarının Hesaplanması**\n   - `fuzzy_risks_train = calculate_fuzzy_risk(X_train)` ve `fuzzy_risks_test = calculate_fuzzy_risk(X_test)`: \n     Bu satırlar, **`X_train`** ve **`X_test`** veri setlerindeki her bir örnek için bulanık risk skorlarını hesaplar. **`calculate_fuzzy_risk()`** fonksiyonu, her bir örnek için diyabet riski skorunu (bulanık bir skor olarak) döndürür.\n   \n   - Bu skorlar, daha sonra özelliklerin (features) arasında yer alacak ve modelin öğrenmesinde kullanılacaktır.\n\n### 2. **Bulanık Risk Skorları ile Diğer Özelliklerin Birleştirilmesi**\n   - `X_train_with_fuzzy = np.hstack((X_train.values, fuzzy_risks_train))`: \n     Burada, **`X_train`** veri setindeki tüm özellikler ile hesaplanan **bulanık risk skorları** (`fuzzy_risks_train`) yatay olarak (sütun bazında) birleştiriliyor.\n     - **`X_train.values`**: Eğitim setindeki orijinal özelliklerin (özelliklerin `DataFrame` formatındaki değerlerini) alır.\n     - **`fuzzy_risks_train`**: Bulanık risk skorları, her bir örneğe karşılık gelen diyabet riskini içerir.\n     - `np.hstack()`: Bu fonksiyon, iki diziyi yatayda (sütun bazında) birleştirir. Sonuç olarak, eğitim setindeki her örneğin orijinal özelliklerine **bulanık risk skoru** eklenmiş olur.\n\n   - Aynı işlem test verisi için de yapılır:\n     - `X_test_with_fuzzy = np.hstack((X_test.values, fuzzy_risks_test))`\n\n### 3. **Verinin Standartlaştırılması**\n   - `scaler = StandardScaler()`: **`StandardScaler`**, veriyi standartlaştırmak için kullanılan bir yöntemdir. Standartlaştırma, her özelliği ortalama 0 ve standart sapma 1 olacak şekilde dönüştürür. Bu, modelin daha hızlı ve doğru öğrenmesini sağlayabilir, çünkü bazı algoritmalar farklı ölçeklerdeki özelliklerle daha iyi çalışmaz.\n   \n   - `X_train_scaled = scaler.fit_transform(X_train_with_fuzzy)`: \n     - `fit_transform()` fonksiyonu, eğitim verisini alır, **ölçekleme parametrelerini (ortalama ve standart sapma)** hesaplar ve veriyi bu parametrelere göre **standartlaştırır**. \n     - **`X_train_with_fuzzy`** burada eğitim verisini içerir, bu veri **bulanık risk skorları** eklenmiş olan veri kümesidir.\n   \n   - `X_test_scaled = scaler.transform(X_test_with_fuzzy)`: \n     - `transform()` fonksiyonu, test verisini aynı standartlara göre dönüştürür. Burada **test verisinin** daha önce hesaplanmış olan eğitim setine dayalı standartlara göre dönüştürülmesi sağlanır.\n\n### 4. **Özellik İsimlerinin Oluşturulması**\n   - `feature_names = list(X_train.columns) + ['fuzzy_risk']`: \n     Burada, eğitim setindeki **özellik isimleri** (`X_train.columns`) alınır ve **`fuzzy_risk`** adlı yeni bir özellik ismi eklenir. Bu yeni özellik, her örnek için hesaplanan diyabet riskini temsil eder.\n   \n   - Sonuç olarak, **özellik isimlerinin** listesi şu şekilde olur:\n     - Örneğin, `['Glucose', 'BMI', 'Age', 'BloodPressure', 'DiabetesPedigreeFunction', 'fuzzy_risk']`\n\n### Özetle:\n1. **Bulanık risk skorları** hesaplanır ve eğitim ve test verilerine eklenir.\n2. **Veri, standartlaştırılır** (özelliklerin ölçekleri normalize edilir).\n3. **Özellik isimleri** oluşturulup kaydedilir.\n\nBu işlem, modelin daha etkili bir şekilde eğitim almasını sağlamak için veri ön işleme aşamasında yaygın olarak kullanılır. Bulanık risk skoru gibi ek özellikler, modelin diyabet riskini daha doğru bir şekilde öğrenmesine yardımcı olabilir.","metadata":{}},{"cell_type":"code","source":"# # Gelişmiş Ensemble modeli\n# # Birden fazla güçlü model ile ağırlıklı oylama yapan bir topluluk modeli\n# ensemble = VotingClassifier(estimators=[\n#     ('rf', RandomForestClassifier(n_estimators=300, max_depth=15, min_samples_split=5, \n#                                  class_weight='balanced', bootstrap=True, random_state=42)),\n#     ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, \n#                                      subsample=0.8, random_state=42)),\n#     ('ada', AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=42)),\n#     ('svm', SVC(C=10, gamma='scale', probability=True, class_weight='balanced', random_state=42)),\n#     ('mlp', MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', alpha=0.0001,\n#                           learning_rate_init=0.001, max_iter=1000, random_state=42))\n# ], voting='soft', weights=[3, 3, 1, 2, 2])\n\n# # 5-katlı çapraz doğrulama ile model performansını değerlendir\n# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# cv_scores = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:25.472628Z","iopub.execute_input":"2025-05-01T13:09:25.472981Z","iopub.status.idle":"2025-05-01T13:09:25.478608Z","shell.execute_reply.started":"2025-05-01T13:09:25.472949Z","shell.execute_reply":"2025-05-01T13:09:25.477755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gelişmiş Ensemble modeli\n# Birden fazla güçlü model ile ağırlıklı oylama yapan bir topluluk modeli\nensemble = VotingClassifier(estimators=[\n    ('rf', RandomForestClassifier(n_estimators=300, max_depth=15, min_samples_split=5, \n                                  class_weight='balanced', bootstrap=True, random_state=42)),\n    ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, \n                                      subsample=0.8, random_state=42)),\n    ('mlp', MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', alpha=0.0001,\n                          learning_rate_init=0.001, max_iter=1000, random_state=42))\n], voting='soft', weights=[3, 4, 1])\n\n# 5-katlı çapraz doğrulama ile model performansını değerlendir\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:25.479872Z","iopub.execute_input":"2025-05-01T13:09:25.480231Z","iopub.status.idle":"2025-05-01T13:09:25.525278Z","shell.execute_reply.started":"2025-05-01T13:09:25.480201Z","shell.execute_reply":"2025-05-01T13:09:25.524311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.model_selection import cross_val_score\n# import numpy as np\n\n# # Kullanacağımız modeller (şu an ensemble'dakilerin birebir aynısı)\n# models = {\n#     'RandomForest': RandomForestClassifier(n_estimators=300, max_depth=15, min_samples_split=5, \n#                                             class_weight='balanced', bootstrap=True, random_state=42),\n#     'GradientBoosting': GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, \n#                                                     subsample=0.8, random_state=42),\n#     'AdaBoost': AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n#     'SVM': SVC(C=10, gamma='scale', probability=True, class_weight='balanced', random_state=42),\n#     'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', alpha=0.0001,\n#                          learning_rate_init=0.001, max_iter=1000, random_state=42)\n# }\n\n# # Sonuçları burada tutacağız\n# results = {}\n\n# # 5-fold stratified cross validation\n# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# # Modelleri sırayla eğit ve doğruluk skorlarını ölç\n# for name, model in models.items():\n#     scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')  # veya roc_auc\n#     results[name] = (np.mean(scores), np.std(scores))\n#     print(f\"{name}: Mean Accuracy = {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:25.526325Z","iopub.execute_input":"2025-05-01T13:09:25.526665Z","iopub.status.idle":"2025-05-01T13:09:25.544810Z","shell.execute_reply.started":"2025-05-01T13:09:25.526629Z","shell.execute_reply":"2025-05-01T13:09:25.543943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Bu kod parçası, sınıf dengesizliğini ele almak için **class_weight** parametresini kullanarak gelişmiş bir **ensemble** modeli oluşturur ve modelin performansını 5-katlı çapraz doğrulama ile değerlendirir. Adım adım açıklayalım:\n\n### 1. **Ensemble Modelinin Tanımlanması:**\n```python\nensemble = VotingClassifier(estimators=[\n    ('rf', RandomForestClassifier(n_estimators=300, max_depth=15, min_samples_split=5, \n                                 class_weight='balanced', bootstrap=True, random_state=42)),\n    ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, \n                                     subsample=0.8, random_state=42)),\n    ('ada', AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=42)),\n    ('svm', SVC(C=10, gamma='scale', probability=True, class_weight='balanced', random_state=42)),\n    ('mlp', MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', alpha=0.0001,\n                          learning_rate_init=0.001, max_iter=1000, random_state=42))\n], voting='soft', weights=[3, 3, 1, 2, 2])\n```\n\nBurada, bir **`VotingClassifier`** ensemble modeli tanımlanıyor. **Ensemble model**, birden fazla temel modelin bir arada çalışarak (oy verme yöntemiyle) tahminler yapmasını sağlar. Bu modelde 5 farklı sınıflandırıcı (model) yer alır:\n\n- **RandomForestClassifier (rf):** 300 ağaçlı, maksimum derinliği 15, her iki sınıf için dengenli ağırlıklar kullanan karar ağacı tabanlı bir model.\n- **GradientBoostingClassifier (gb):** 200 ağaçlı, öğrenme oranı 0.1 olan, derinliği 5 olan bir boosting modeli.\n- **AdaBoostClassifier (ada):** 100 zayıf modelin (genellikle karar ağaçları) birleşimiyle çalışan bir boosting modeli.\n- **SVC (svm):** Destek Vektör Makinesi (SVM) sınıflandırıcısı. `class_weight='balanced'` parametresi, sınıf dengesizliğini dengelemek için ağırlıkların otomatik olarak ayarlanmasını sağlar.\n- **MLPClassifier (mlp):** Çok Katmanlı Perceptron (MLP) sınıflandırıcısı, sinir ağı tabanlı bir model.\n\n**`voting='soft'`**: Bu parametre, \"soft\" oylama yöntemi kullanır. Yani, her bir sınıflandırıcının tahmin ettiği olasılıkların ortalaması alınır ve en yüksek olasılığa sahip sınıf seçilir.\n\n**`weights=[3, 3, 1, 2, 2]`**: Bu, her bir modelin oylama sürecindeki ağırlıklarını belirtir. Örneğin, RandomForest ve GradientBoosting sınıflandırıcıları daha yüksek ağırlığa (3) sahipken, AdaBoost'un ağırlığı 1'dir.\n\n### 2. **5-Katlı Çapraz Doğrulama:**\n```python\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = []\n\nfor train_idx, val_idx in cv.split(X_train_scaled, y_train):\n    # Eğitim ve doğrulama setlerini ayır\n    X_cv_train, X_cv_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n    y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n    \n    # Modeli eğit\n    ensemble.fit(X_cv_train, y_cv_train)\n    \n    # Doğrulama setinde tahmin yap\n    y_cv_pred = ensemble.predict(X_cv_val)\n    \n    # Doğruluğu hesapla\n    accuracy = accuracy_score(y_cv_val, y_cv_pred)\n    cv_scores.append(accuracy)\n```\n\n#### a. **StratifiedKFold:**\n- **`StratifiedKFold`**: Veri setini 5 katmana böler (5-katlı çapraz doğrulama). `n_splits=5`, bu çapraz doğrulamanın 5 katmanla yapılacağını belirtir. **`shuffle=True`**, verileri karıştırarak daha iyi bir doğrulama sağlar. **`random_state=42`**, aynı veri setiyle tekrar çalışırken sonuçların tutarlı olmasını sağlar.\n- **Stratified**: Bu parametre, her katmanda sınıfların dağılımının, tüm veri setindeki dağılıma benzer olmasını sağlar (yani, her katmanda her sınıfın oranı korunur).\n\n#### b. **Eğitim ve Doğrulama Setlerinin Ayrılması:**\n- **`train_idx, val_idx`**: `cv.split()` fonksiyonu, eğitim ve doğrulama setlerine ayırmak için indeksleri döndürür. `train_idx` eğitim setindeki örneklerin indekslerini, `val_idx` doğrulama setindeki örneklerin indekslerini verir.\n- `X_cv_train, X_cv_val`: Eğitim ve doğrulama setlerinin özellikleri.\n- `y_cv_train, y_cv_val`: Eğitim ve doğrulama setlerinin etiketleri.\n\n#### c. **Model Eğitimi ve Tahmin:**\n- **`ensemble.fit(X_cv_train, y_cv_train)`**: Her katmanda, ensemble modelini eğitim verileriyle eğitir.\n- **`y_cv_pred = ensemble.predict(X_cv_val)`**: Doğrulama seti üzerinde tahmin yapar.\n\n#### d. **Doğruluk Hesaplama:**\n- **`accuracy = accuracy_score(y_cv_val, y_cv_pred)`**: Doğruluk (accuracy) skoru hesaplanır, yani modelin doğrulama setindeki doğru tahminlerinin oranı.\n\n#### e. **Sonuçların Kaydedilmesi:**\n- **`cv_scores.append(accuracy)`**: Her katmandaki doğruluk skoru kaydedilir.\n\n### 3. **Sonuçların Yazdırılması:**\n```python\nprint(f\"5-katlı çapraz doğrulama skoru: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n```\n- **`np.mean(cv_scores)`**: Çapraz doğrulama sonuçlarının ortalamasını alır.\n- **`np.std(cv_scores)`**: Çapraz doğrulama sonuçlarının standart sapmasını alır.\n- **Yazdırma**: Ortalama doğruluk ve standart sapma ekrana yazdırılır. Bu, modelin genel performansını ve ne kadar değişkenlik gösterdiğini gösterir.\n\n### Özet:\nBu kod, sınıf dengesizliği için `class_weight='balanced'` parametresini kullanan ve çeşitli temel sınıflandırıcıları içeren bir **ensemble model** kurar. Ardından, bu modelin performansını 5-katlı çapraz doğrulama ile değerlendirir ve doğruluk ortalamasını ve standart sapmasını hesaplar.\n\n# Final modeli tüm eğitim verisi üzerinde eğit\nensemble.fit(X_train_scaled, y_train)\n\n# Test seti üzerinde tahmin yap\ny_pred = ensemble.predict(X_test_scaled)\ny_pred_proba = ensemble.predict_proba(X_test_scaled)[:, 1]\n\n# Sonuçları değerlendir\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test seti doğruluğu: {accuracy:.4f}\")\nprint(\"\\nSınıflandırma Raporu:\\n\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T07:51:32.772736Z","iopub.execute_input":"2025-05-02T07:51:32.773067Z","iopub.status.idle":"2025-05-02T07:51:32.792900Z","shell.execute_reply.started":"2025-05-02T07:51:32.773043Z","shell.execute_reply":"2025-05-02T07:51:32.791554Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_31/2272272493.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Bu kod parçası, sınıf dengesizliğini ele almak için **class_weight** parametresini kullanarak gelişmiş bir **ensemble** modeli oluşturur ve modelin performansını 5-katlı çapraz doğrulama ile değerlendirir. Adım adım açıklayalım:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (2272272493.py, line 1)","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"for train_idx, val_idx in cv.split(X_train_scaled, y_train):\n    # Eğitim ve doğrulama setlerini ayır\n    X_cv_train, X_cv_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n    y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n    \n    # Modeli eğit\n    ensemble.fit(X_cv_train, y_cv_train)\n    \n    # Doğrulama setinde tahmin yap\n    y_cv_pred = ensemble.predict(X_cv_val)\n    \n    # Doğruluğu hesapla\n    accuracy = accuracy_score(y_cv_val, y_cv_pred)\n    cv_scores.append(accuracy)\n\nprint(f\"5-katlı çapraz doğrulama skoru: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n\n# Final modeli tüm eğitim verisi üzerinde eğit\nensemble.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:25.545689Z","iopub.execute_input":"2025-05-01T13:09:25.546041Z","iopub.status.idle":"2025-05-01T13:09:52.072799Z","shell.execute_reply.started":"2025-05-01T13:09:25.545992Z","shell.execute_reply":"2025-05-01T13:09:52.071972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test seti üzerinde tahmin yap\ny_pred = ensemble.predict(X_test_scaled)\ny_pred_proba = ensemble.predict_proba(X_test_scaled)[:, 1]\n\n# Sonuçları değerlendir\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test seti doğruluğu: {accuracy:.4f}\")\nprint(\"\\nSınıflandırma Raporu:\\n\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:52.073640Z","iopub.execute_input":"2025-05-01T13:09:52.073916Z","iopub.status.idle":"2025-05-01T13:09:52.151903Z","shell.execute_reply.started":"2025-05-01T13:09:52.073897Z","shell.execute_reply":"2025-05-01T13:09:52.151062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Karışıklık matrisi\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nplt.imshow(cm, cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Tahmin Edilen')\nplt.ylabel('Gerçek')\nplt.xticks([0, 1], ['Sağlıklı (0)', 'Hasta (1)'])\nplt.yticks([0, 1], ['Sağlıklı (0)', 'Hasta (1)'])\n\nfor i in range(2):\n    for j in range(2):\n        plt.text(j, i, cm[i, j], ha='center', va='center', color='red', fontsize=16)\n\nplt.colorbar()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:52.154982Z","iopub.execute_input":"2025-05-01T13:09:52.155282Z","iopub.status.idle":"2025-05-01T13:09:52.458155Z","shell.execute_reply.started":"2025-05-01T13:09:52.155261Z","shell.execute_reply":"2025-05-01T13:09:52.457237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Eğrisi\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Eğrisi (AUC = {roc_auc:.3f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Eğrisi')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:52.458767Z","iopub.execute_input":"2025-05-01T13:09:52.459054Z","iopub.status.idle":"2025-05-01T13:09:52.651319Z","shell.execute_reply.started":"2025-05-01T13:09:52.459035Z","shell.execute_reply":"2025-05-01T13:09:52.650312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Öznitelik önemlerini görselleştir (Random Forest ile)\nrf_model = RandomForestClassifier(n_estimators=300, random_state=42)\nrf_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:52.652317Z","iopub.execute_input":"2025-05-01T13:09:52.652592Z","iopub.status.idle":"2025-05-01T13:09:53.464239Z","shell.execute_reply.started":"2025-05-01T13:09:52.652573Z","shell.execute_reply":"2025-05-01T13:09:53.463266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Özellik önemlerini görselleştir\nplt.figure(figsize=(10, 8))\nimportances = rf_model.feature_importances_\nindices = np.argsort(importances)[::-1]\n\nplt.title('Özellik Önemleri')\nplt.bar(range(X_train_scaled.shape[1]), importances[indices], align='center')\nplt.xticks(range(X_train_scaled.shape[1]), [feature_names[i] for i in indices], rotation=90)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:53.465466Z","iopub.execute_input":"2025-05-01T13:09:53.465803Z","iopub.status.idle":"2025-05-01T13:09:53.767544Z","shell.execute_reply.started":"2025-05-01T13:09:53.465769Z","shell.execute_reply":"2025-05-01T13:09:53.766665Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bu kod, modelin **5-katlı çapraz doğrulama** ile performansını değerlendirip, ardından **test seti üzerinde tahmin** yaparak sonuçları raporluyor. Ayrıca, **karışıklık matrisi**, **ROC eğrisi** ve **özelliklerin önemi** gibi görselleştirmeler de içeriyor. Şimdi, her kısmı detaylı bir şekilde açıklayalım:\n\n### 1. **5-Katlı Çapraz Doğrulama**\n```python\nfor train_idx, val_idx in cv.split(X_train_scaled, y_train):\n    # Eğitim ve doğrulama setlerini ayır\n    X_cv_train, X_cv_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n    y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n    \n    # Modeli eğit\n    ensemble.fit(X_cv_train, y_cv_train)\n    \n    # Doğrulama setinde tahmin yap\n    y_cv_pred = ensemble.predict(X_cv_val)\n    \n    # Doğruluğu hesapla\n    accuracy = accuracy_score(y_cv_val, y_cv_pred)\n    cv_scores.append(accuracy)\n\nprint(f\"5-katlı çapraz doğrulama skoru: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n```\n\n- **Çapraz doğrulama (CV)**, modelin genellenebilirliğini değerlendirmek için kullanılır. Burada 5-katlı çapraz doğrulama yapılmaktadır:\n  - **`cv.split(X_train_scaled, y_train)`**: Eğitim verisini 5 katmana böler. Her bir katman sırasıyla doğrulama seti olarak kullanılır.\n  - **Modelin eğitilmesi (`ensemble.fit`)** ve doğrulama setinde tahmin yapması (`ensemble.predict`).\n  - **`accuracy_score(y_cv_val, y_cv_pred)`**: Her katmanda doğruluk skoru hesaplanır ve **cv_scores** listesine eklenir.\n  - Son olarak, **ortalama doğruluk** ve **standart sapma** hesaplanır.\n\n### 2. **Final Modeli ve Test Seti Üzerinde Tahmin**\n```python\n# Final modeli tüm eğitim verisi üzerinde eğit\nensemble.fit(X_train_scaled, y_train)\n\n# Test seti üzerinde tahmin yap\ny_pred = ensemble.predict(X_test_scaled)\ny_pred_proba = ensemble.predict_proba(X_test_scaled)[:, 1]\n```\n\n- **Modeli tüm eğitim verisi ile eğitme**: `ensemble.fit(X_train_scaled, y_train)` ile, en son model tüm eğitim verisiyle yeniden eğitilir.\n- **Test verisi üzerinde tahmin yapma**:\n  - **`y_pred = ensemble.predict(X_test_scaled)`**: Test setindeki sınıflar tahmin edilir.\n  - **`y_pred_proba = ensemble.predict_proba(X_test_scaled)[:, 1]`**: Ayrıca, her sınıfın olasılıkları tahmin edilir (özellikle 1. sınıf için, çünkü ikili sınıflandırma yapılıyor).\n\n### 3. **Sonuçların Değerlendirilmesi**\n#### Doğruluk ve Sınıflandırma Raporu\n```python\n# Sonuçları değerlendir\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test seti doğruluğu: {accuracy:.4f}\")\nprint(\"\\nSınıflandırma Raporu:\\n\")\nprint(classification_report(y_test, y_pred))\n```\n- **`accuracy_score(y_test, y_pred)`**: Test seti üzerinde modelin doğruluğu hesaplanır.\n- **`classification_report(y_test, y_pred)`**: Modelin doğruluğunun yanı sıra, **precision**, **recall**, **f1-score** gibi daha ayrıntılı metriklerin raporlanmasını sağlar.\n\n#### Karışıklık Matrisi Görselleştirmesi\n```python\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nplt.imshow(cm, cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Tahmin Edilen')\nplt.ylabel('Gerçek')\nplt.xticks([0, 1], ['Sağlıklı (0)', 'Hasta (1)'])\nplt.yticks([0, 1], ['Sağlıklı (0)', 'Hasta (1)'])\n\nfor i in range(2):\n    for j in range(2):\n        plt.text(j, i, cm[i, j], ha='center', va='center', color='red', fontsize=16)\n\nplt.colorbar()\nplt.show()\n```\n\n- **Karışıklık matrisi**: Modelin doğru ve yanlış tahminlerini görselleştiren bir **confusion matrix** oluşturulur.\n  - **`cm[i, j]`**: Gerçek etiketler ile tahmin edilen etiketler arasındaki ilişkileri temsil eder.\n  - **Görselleştirme**: Matris, `imshow` ile renkli bir şekilde görselleştirilir. **Kırmızı** renkli sayılar, her hücredeki değeri belirtir.\n\n#### ROC Eğrisi\n```python\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Eğrisi (AUC = {roc_auc:.3f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Eğrisi')\nplt.legend(loc=\"lower right\")\nplt.show()\n```\n\n- **ROC eğrisi**: **Receiver Operating Characteristic (ROC)** eğrisini çizer. Bu eğri, **True Positive Rate (TPR)** ve **False Positive Rate (FPR)** değerleri arasında gösterilir.\n- **AUC (Area Under the Curve)**: Bu eğrinin altındaki alan, modelin genel başarısını özetler. AUC değeri 1'e yaklaştıkça modelin başarısı artar.\n\n### 4. **Özellik Önemlerinin Görselleştirilmesi**\n```python\nrf_model = RandomForestClassifier(n_estimators=300, random_state=42)\nrf_model.fit(X_train_scaled, y_train)\n\nplt.figure(figsize=(10, 8))\nimportances = rf_model.feature_importances_\nindices = np.argsort(importances)[::-1]\n\nplt.title('Özellik Önemleri')\nplt.bar(range(X_train_scaled.shape[1]), importances[indices], align='center')\nplt.xticks(range(X_train_scaled.shape[1]), [feature_names[i] for i in indices], rotation=90)\nplt.tight_layout()\nplt.show()\n```\n\n- **Özelliklerin önemi**: `RandomForestClassifier` kullanarak her özelliğin modelin kararına katkısını ölçeriz.\n  - **`importances = rf_model.feature_importances_`**: Model, her özelliğin model kararına olan katkısını hesaplar.\n  - **`np.argsort(importances)`**: Bu, özellikleri önem sırasına göre sıralar.\n  - **Bar grafiği**: Özelliklerin önemlerini görselleştiren bir bar grafiği oluşturulur. Bu, hangi özelliklerin modelin tahminine en fazla katkı sağladığını gösterir.\n\n### Özet:\n- **5-Katlı Çapraz Doğrulama**: Modelin genel performansını daha sağlam bir şekilde değerlendirir.\n- **Test Seti Üzerinde Performans**: Son modelin test verisi üzerindeki doğruluğu, karışıklık matrisi ve sınıflandırma raporu ile değerlendirilir.\n- **ROC Eğrisi**: Modelin sınıflandırma başarısını görsel olarak sunar.\n- **Özellik Önemleri**: Hangi özelliklerin model için daha önemli olduğunu görselleştirir.","metadata":{}},{"cell_type":"code","source":"# Tahmin eşiğini optimize ederek performansı artır\n# Farklı tahmin eşiklerini dene\nthresholds = np.arange(0.3, 0.8, 0.05)\naccuracies = []\n\nfor threshold in thresholds:\n    y_pred_optimized = (y_pred_proba >= threshold).astype(int)\n    accuracies.append(accuracy_score(y_test, y_pred_optimized))\n\n# En iyi eşiği bul\nbest_threshold_idx = np.argmax(accuracies)\nbest_threshold = thresholds[best_threshold_idx]\nbest_accuracy = accuracies[best_threshold_idx]\n\nprint(f\"En iyi eşik: {best_threshold:.2f}, Doğruluk: {best_accuracy:.4f}\")\n\n# En iyi eşik ile final tahminleri oluştur\ny_pred_best = (y_pred_proba >= best_threshold).astype(int)\nprint(\"\\nOptimize Edilmiş Eşik ile Sınıflandırma Raporu:\\n\")\nprint(classification_report(y_test, y_pred_best))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:53.768728Z","iopub.execute_input":"2025-05-01T13:09:53.769070Z","iopub.status.idle":"2025-05-01T13:09:53.792409Z","shell.execute_reply.started":"2025-05-01T13:09:53.769040Z","shell.execute_reply":"2025-05-01T13:09:53.791472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Önemli özellikleri görselleştir\n# Örnek bir vakanın risk değerlendirmesi\nexample_idx = 0  # İlk test örneği\nexample_data = X_test.iloc[example_idx]\nexample_risk = fuzzy_risks_test[example_idx][0]\nexample_true_label = y_test.iloc[example_idx]\nexample_pred_label = y_pred[example_idx]\n\nprint(f\"\\nÖrnek Vaka Analizi (Index: {example_idx}):\")\nprint(f\"Glukoz: {example_data['Glucose']:.1f}\")\nprint(f\"BMI: {example_data['BMI']:.1f}\")\nprint(f\"Yaş: {example_data['Age']:.1f}\")\nprint(f\"Kan Basıncı: {example_data['BloodPressure']:.1f}\")\nprint(f\"Pedigree Fonksiyonu: {example_data['DiabetesPedigreeFunction']:.3f}\")\nprint(f\"Bulanık Risk Skoru: {example_risk:.1f}\")\nprint(f\"Gerçek Etiket: {'Hasta' if example_true_label == 1 else 'Sağlıklı'}\")\nprint(f\"Tahmin Edilen Etiket: {'Hasta' if example_pred_label == 1 else 'Sağlıklı'}\")\nprint(f\"Diyabet Olasılığı: {y_pred_proba[example_idx]:.3f}\")\n\n# Fuzzy sistemin üyelik fonksiyonlarını görselleştir\n# Fuzzy sistemin üyelik fonksiyonlarını görselleştir\nrules, glucose, bmi, age, bloodpressure, pedigree, diabetes_risk = create_fuzzy_system()\n\nfig, axes = plt.subplots(3, 2, figsize=(15, 15))\n\n# 1. grafik\nglucose.view(ax=axes[0, 0])\naxes[0, 0].set_title('Glukoz Üyelik Fonksiyonları')\naxes[0, 0].set_xlabel('Glukoz Seviyesi')\naxes[0, 0].set_ylabel('Üyelik Derecesi')\n\n# 2. grafik\nbmi.view(ax=axes[0, 1])\naxes[0, 1].set_title('BMI Üyelik Fonksiyonları')\naxes[0, 1].set_xlabel('BMI Değeri')\naxes[0, 1].set_ylabel('Üyelik Derecesi')\n\n# 3. grafik\nage.view(ax=axes[1, 0])\naxes[1, 0].set_title('Yaş Üyelik Fonksiyonları')\naxes[1, 0].set_xlabel('Yaş')\naxes[1, 0].set_ylabel('Üyelik Derecesi')\n\n# 4. grafik\nbloodpressure.view(ax=axes[1, 1])\naxes[1, 1].set_title('Kan Basıncı Üyelik Fonksiyonları')\naxes[1, 1].set_xlabel('Kan Basıncı')\naxes[1, 1].set_ylabel('Üyelik Derecesi')\n\n# 5. grafik\npedigree.view(ax=axes[2, 0])\naxes[2, 0].set_title('Genetik Yatkınlık Üyelik Fonksiyonları')\naxes[2, 0].set_xlabel('Diyabet Soy Geçmişi Fonksiyonu')\naxes[2, 0].set_ylabel('Üyelik Derecesi')\n\n# 6. grafik\ndiabetes_risk.view(ax=axes[2, 1])\naxes[2, 1].set_title('Diyabet Risk Üyelik Fonksiyonları')\naxes[2, 1].set_xlabel('Risk Seviyesi')\naxes[2, 1].set_ylabel('Üyelik Derecesi')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:53.793381Z","iopub.execute_input":"2025-05-01T13:09:53.793626Z","iopub.status.idle":"2025-05-01T13:09:55.877254Z","shell.execute_reply.started":"2025-05-01T13:09:53.793598Z","shell.execute_reply":"2025-05-01T13:09:55.876119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Özellik çiftlerinin ilişkisini görselleştir (renkler gerçek sınıfı gösterir)\nplt.figure(figsize=(12, 10))\nplt.scatter(X_test['Glucose'], X_test['BMI'], c=y_test, cmap='coolwarm', \n            edgecolor='k', s=80, alpha=0.7)\nplt.colorbar(label='Diyabet Durumu')\nplt.title('Glukoz ve BMI İlişkisi')\nplt.xlabel('Glukoz')\nplt.ylabel('BMI')\nplt.grid(True, alpha=0.3)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:55.878316Z","iopub.execute_input":"2025-05-01T13:09:55.878573Z","iopub.status.idle":"2025-05-01T13:09:56.200939Z","shell.execute_reply.started":"2025-05-01T13:09:55.878555Z","shell.execute_reply":"2025-05-01T13:09:56.199948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tahmin hataları analizi - hangi durumlarda model hata yapıyor?\nerrors = y_test != y_pred\nX_errors = X_test[errors]\ny_errors = y_test[errors]\n\nprint(f\"\\nHata Yapılan Örneklerin Analizi (Toplam {np.sum(errors)} hata):\")\nfor feature in ['Glucose', 'BMI', 'Age', 'BloodPressure', 'DiabetesPedigreeFunction']:\n    print(f\"{feature} - Ortalama: {X_errors[feature].mean():.2f}, Min: {X_errors[feature].min():.2f}, Max: {X_errors[feature].max():.2f}\")\n\n# Sınıflar arası dengesizliği görselleştir\nplt.figure(figsize=(8, 6))\nplt.bar(['Sağlıklı (0)', 'Hasta (1)'], [np.sum(y_test == 0), np.sum(y_test == 1)])\nplt.title('Test Verisi Sınıf Dağılımı')\nplt.ylabel('Örnek Sayısı')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:56.201840Z","iopub.execute_input":"2025-05-01T13:09:56.202167Z","iopub.status.idle":"2025-05-01T13:09:56.367035Z","shell.execute_reply.started":"2025-05-01T13:09:56.202143Z","shell.execute_reply":"2025-05-01T13:09:56.366235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final model performansı özeti\nprint(\"\\nFinal Model Performans Özeti:\")\nprint(f\"Doğruluk: {accuracy:.4f}\")\nprint(f\"ROC AUC: {roc_auc:.4f}\")\nprint(f\"Optimum Eşik ile Doğruluk: {best_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T13:09:56.368040Z","iopub.execute_input":"2025-05-01T13:09:56.368296Z","iopub.status.idle":"2025-05-01T13:09:56.374514Z","shell.execute_reply.started":"2025-05-01T13:09:56.368267Z","shell.execute_reply":"2025-05-01T13:09:56.373525Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Tabii, burada çeşitli adımlar yer alıyor. Kodun her bölümünü açıklayarak ilerleyelim:\n\n### 1. **Tahmin Eşiğini Optimize Etme**\n   - **Farklı eşik değerlerini deneme:** Bu adımda, modelin sınıflandırma kararlarını belirlemek için kullanılan eşik değeri optimize ediliyor. Başlangıçta, modelin doğruluk skoru (accuracy), varsayılan eşik olan 0.5'e dayanarak hesaplanıyor. Ancak eşik değeri değiştirmek, modelin performansını iyileştirebilir.\n   \n   - **Threshold Loop:** Eşik değerleri `np.arange(0.3, 0.8, 0.05)` arasında değiştiriliyor. Bu eşikler, modelin tahminini hangi değere göre sınıflandıracağını belirler. Örneğin, 0.4 eşik değeriyle, modelin tahminini 0.4 veya daha yüksek bir olasılıkla `1` (hasta) olarak sınıflandırırsınız.\n\n   - **En iyi eşik değeri bulma:** Tüm eşik değerleri için doğruluk hesaplanır ve en iyi doğruluk sağlayan eşik değeri seçilir.\n\n### 2. **Optimum Eşik ile Final Tahminleri**\n   - **En iyi eşik ile final tahminleri:** En iyi eşik bulunduğunda, tahminler bu eşikle güncellenir ve `classification_report` fonksiyonu ile optimize edilmiş modelin performansı değerlendirilir. Bu rapor, doğruluk, precision, recall, f1 skoru gibi metrikleri içerir.\n\n### 3. **Fuzzy Sistem ve Üyelik Fonksiyonları**\n   - **Fuzzy sistemin üyelik fonksiyonlarını görselleştirme:** Burada, diyabet riskini tahmin etmek için kullanılan fuzzy mantık üyelik fonksiyonları görselleştiriliyor. Fuzzy sistemde, her bir özellik (glukoz, BMI, yaş, kan basıncı vb.) için bir üyelik fonksiyonu vardır. Bu fonksiyonlar, özelliklerin değerleri ile belirli üyelik derecelerini ilişkilendirir.\n\n   - **Üyelik fonksiyonları:** Örneğin, `Glucose`, `BMI`, `Age` gibi özelliklerin üyelik fonksiyonları, o özelliğin diyabet riskine ne kadar katkı sağladığını gösterir. Grafiklerde bu fonksiyonlar, değerlerin üyelik derecelerine karşılık gelen eğriler olarak gösterilir.\n\n### 4. **Özelliklerin İlişkisi ve Visualizations**\n   - **Özellik çiftlerinin ilişkisini görselleştirme:** Burada, `Glucose` ve `BMI` gibi özelliklerin test verisindeki ilişkisi görselleştirilir. Özellikler arasındaki korelasyon ve modelin sınıf tahminlerine (hasta/sağlıklı) olan etkisini görselleştiririz.\n   \n   - **Renklerle sınıf gösterimi:** Scatter plot kullanılarak bu ilişkiler görselleştirilir. Renkler, veri noktalarının sağlıklı (`0`) veya hasta (`1`) olma durumlarını gösterir.\n\n### 5. **Tahmin Hataları Analizi**\n   - **Tahmin hatalarının analizi:** Modelin yaptığı hataları analiz ederiz. `errors` dizisi, tahminlerin yanlış olduğu yerleri belirler. Bu yanlış tahminlerin hangi özelliklerde yoğunlaştığını inceleyerek modelin hangi durumlarda hata yaptığını anlamaya çalışırız.\n\n### 6. **Sınıf Dengesizliği Görselleştirme**\n   - **Sınıf dengesizliği:** Test verisindeki sınıfların (sağlıklı ve hasta) dağılımı görselleştirilir. Bu, sınıflar arasındaki dengesizliği (örneğin, hasta sınıfının daha fazla olması) göstermek için kullanılır. Eğer veri setinde ciddi bir dengesizlik varsa, modelin performansını iyileştirmek için bazı teknikler uygulanabilir (örneğin, SMOTE).\n\n### 7. **Final Model Performansı Özeti**\n   - **Final modelin doğruluğu:** Modelin final performansı özetlenir. Bu, doğruluk, ROC AUC gibi metrikleri içerir. Ayrıca, en iyi eşik ile yapılan tahminlerin doğruluğu da gösterilir.\n\n**Özetle:** \n- Kod, modelin doğruluk performansını optimize etmek için tahmin eşiklerini değiştirmeyi içerir.\n- Modelin sonuçlarını, görselleştirmeler ve analizlerle destekler.\n- Bu süreçler, modelin doğruluğunu, özelliklerin etkisini ve tahmin hatalarını daha iyi anlamanızı sağlar.\n\nUmarım açıklamalar yardımcı olmuştur! Başka bir şey sormak isterseniz, yardımcı olmaktan memnuniyet duyarım.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}